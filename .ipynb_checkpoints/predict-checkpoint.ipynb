{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from data_helper import read_data, sents2sequences\n",
    "from model import summary_model\n",
    "from model_helper import plot_attention_weights\n",
    "from logger import get_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = '/home/swayam/Desktop/tf2_project/'\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.train | INFO | Started log /home/swayam/Desktop/tf2_project/logs/model.train\n"
     ]
    }
   ],
   "source": [
    "base_dir = '/home/swayam/Desktop/tf2_project/'\n",
    "logger = get_logger(\"model.train\",os.path.join(base_dir, 'logs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "hidden_size = 96\n",
    "ip_timesteps, op_timesteps = 20, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_size, random_seed=100):\n",
    "#randomly shuffle train/test\n",
    "\n",
    "    ip_text = read_data(os.path.join(project_path, 'data', 'text.txt'))\n",
    "    op_text = read_data(os.path.join(project_path, 'data', 'summary.txt'))\n",
    "\n",
    "    op_text = ['sos ' + sent[:-1] + 'eos .'  if sent.endswith('.') else 'sos ' + sent + ' eos .' for sent in op_text]\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "    inds = np.arange(len(ip_text))\n",
    "    np.random.shuffle(inds)\n",
    "\n",
    "    train_inds = inds[:train_size]\n",
    "    test_inds = inds[train_size:]\n",
    "    tr_ip_text = [ip_text[ti] for ti in train_inds]\n",
    "    tr_op_text = [op_text[ti] for ti in train_inds]\n",
    "\n",
    "    ts_ip_text = [ip_text[ti] for ti in test_inds]\n",
    "    ts_op_text = [op_text[ti] for ti in test_inds]\n",
    "\n",
    "    return tr_ip_text, tr_op_text, ts_ip_text, ts_op_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(ip_tokenizer, op_tokenizer, ip_text, op_text, in_timesteps, op_timesteps):\n",
    "#Preprocessing and generating sequence of word indices\n",
    "\n",
    "    ip_seq = sents2sequences(ip_tokenizer, ip_text, reverse=False, padding_type='pre', pad_length=ip_timesteps)\n",
    "    op_seq = sents2sequences(op_tokenizer, op_text, pad_length=op_timesteps)\n",
    "\n",
    "    return ip_seq, op_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_nmt(encoder_model, decoder_model, test_ip_seq, ip_vsize, op_vsize):\n",
    "    \"\"\"\n",
    "    Infer logic\n",
    "    :param encoder_model: keras.Model\n",
    "    :param decoder_model: keras.Model\n",
    "    :param test_ip_seq: sequence of word ids\n",
    "    :param ip_vsize: int\n",
    "    :param op_vsize: int\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    test_op_seq = sents2sequences(op_tokenizer, ['sos'], op_vsize)\n",
    "    test_ip_onehot_seq = to_categorical(test_ip_seq, num_classes=ip_vsize)\n",
    "    test_op_onehot_seq = np.expand_dims(to_categorical(test_op_seq, num_classes=op_vsize), 1)\n",
    "\n",
    "    enc_outs, enc_last_state = encoder_model.predict(test_ip_onehot_seq)\n",
    "    dec_state = enc_last_state\n",
    "    attention_weights = []\n",
    "    op_text = ''\n",
    "    for i in range(20):\n",
    "\n",
    "        dec_out, attention, dec_state = decoder_model.predict([enc_outs, dec_state, test_op_onehot_seq])\n",
    "        dec_ind = np.argmax(dec_out, axis=-1)[0, 0]\n",
    "\n",
    "        if dec_ind == 0:\n",
    "            break\n",
    "        test_op_seq = sents2sequences(op_tokenizer, [op_index2word[dec_ind]], op_vsize)\n",
    "        test_op_onehot_seq = np.expand_dims(to_categorical(test_op_seq, num_classes=op_vsize), 1)\n",
    "\n",
    "        attention_weights.append((dec_ind, attention))\n",
    "        op_text += op_index2word[dec_ind] + ' '\n",
    "\n",
    "    return op_text, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.train | INFO | input_text: Our primary reason for buying this product is that it came in a variety pack.  We make most of our own baby food, but we were going on vacation and that was going to be difficult.  Since packing space was limited, we had this shipped to our destination.  It was the only brand we could find to order in a variety pack.  The kids liked all the flavors and the consistency seemed good.\n",
      "\n",
      "model.train | INFO | output_summary: earth's best variety pack eos \n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    debug = True\n",
    "\n",
    "    train_size = 100000 if not debug else 8000\n",
    "    filename = ''\n",
    "\n",
    "    tr_ip_text, tr_op_text, ts_ip_text, ts_op_text = get_data(train_size=train_size)\n",
    "\n",
    "#Defining tokenizers\n",
    "    ip_tokenizer = keras.preprocessing.text.Tokenizer(oov_token='UNK')\n",
    "    ip_tokenizer.fit_on_texts(tr_ip_text)\n",
    "\n",
    "    op_tokenizer = keras.preprocessing.text.Tokenizer(oov_token='UNK')\n",
    "    op_tokenizer.fit_on_texts(tr_op_text)\n",
    "\n",
    "#Getting preprocessed data\n",
    "    ip_seq, op_seq = preprocess_data(ip_tokenizer, op_tokenizer, tr_ip_text, tr_op_text, ip_timesteps, op_timesteps)\n",
    "\n",
    "    ip_vsize = max(ip_tokenizer.index_word.keys()) + 1\n",
    "    op_vsize = max(op_tokenizer.index_word.keys()) + 1\n",
    "\n",
    "#Defining the full model\n",
    "    full_model, infer_enc_model, infer_dec_model = summary_model(hidden_size=hidden_size, batch_size=batch_size,\n",
    "        ip_timesteps=ip_timesteps, op_timesteps=op_timesteps,ip_vsize=ip_vsize, op_vsize=op_vsize)\n",
    "\n",
    "#load model\n",
    "    full_model.load_weights('/home/swayam/Desktop/tf2_project/summarizer.h5')\n",
    "\n",
    "#Index2word\n",
    "    ip_index2word = dict(zip(ip_tokenizer.word_index.values(), ip_tokenizer.word_index.keys()))\n",
    "    op_index2word = dict(zip(op_tokenizer.word_index.values(), op_tokenizer.word_index.keys()))\n",
    "\n",
    "#inference\n",
    "    test_ip = tr_ip_text[110]\n",
    "    logger.info('input_text: {}'.format(test_ip))\n",
    "    test_ip_seq = sents2sequences(ip_tokenizer, [test_ip], pad_length=ip_timesteps)\n",
    "    test_op, attn_weights = infer_nmt(encoder_model=infer_enc_model, decoder_model=infer_dec_model,test_ip_seq=test_ip_seq, ip_vsize=ip_vsize, op_vsize=op_vsize)\n",
    "    logger.info('output_summary: {}'.format(test_op))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
